[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_CN.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [æ—¥æœ¬èª](README_JP.md)

# GLM-TTS å¢å¼·ç‰ˆï¼šç”Ÿç”¢ç´š TTS æœå‹™

[![Docker Hub](https://img.shields.io/docker/v/neosun/glm-tts?label=Docker%20Hub)](https://hub.docker.com/r/neosun/glm-tts)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![CUDA](https://img.shields.io/badge/CUDA-12.1-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![Python](https://img.shields.io/badge/Python-3.10--3.12-blue.svg)](https://www.python.org/)

GLM-TTS çš„å¢å¼·ç‰ˆæœ¬ï¼Œæä¾›ç”Ÿç”¢ç´šåŠŸèƒ½ï¼šWeb UIã€REST APIã€Whisper è‡ªå‹•è½‰éŒ„å’Œ Docker éƒ¨ç½²ã€‚

![GLM-TTS Enhanced UI](https://img.aws.xin/uPic/YD5e2C.png)

## âœ¨ å¢å¼·åŠŸèƒ½

### ğŸ¯ æ ¸å¿ƒå¢å¼·
- **ğŸŒ ç¾ä»£åŒ– Web ä»‹é¢**ï¼šéŸ¿æ‡‰å¼ä»‹é¢ï¼Œå³æ™‚é€²åº¦è¿½è¹¤
- **ğŸ”Œ REST API**ï¼šå®Œæ•´çš„ APIï¼ŒSwagger æ–‡ä»¶ä½æ–¼ `/apidocs`
- **ğŸ¤ Whisper æ•´åˆ**ï¼šåƒè€ƒæ–‡å­—ç‚ºç©ºæ™‚è‡ªå‹•éŸ³è¨Šè½‰éŒ„
- **ğŸ“Š å³æ™‚é€²åº¦**ï¼šåŸºæ–¼ SSE çš„ä¸²æµå‚³è¼¸ï¼Œé¡¯ç¤ºè€—æ™‚
- **ğŸ³ ä¸€é«”åŒ– Docker**ï¼š23.6GB æ˜ åƒåŒ…å«æ‰€æœ‰æ¨¡å‹å’Œä¾è³´
- **âš¡ GPU å„ªåŒ–**ï¼šcuDNN 9 æ”¯æ´ ONNX Runtime GPU åŠ é€Ÿ
- **ğŸ’¾ æŒä¹…åŒ–å„²å­˜**ï¼šæ›è¼‰ä¸»æ©Ÿç›®éŒ„é€²è¡Œæª”æ¡ˆç®¡ç†
- **ğŸ”§ é€²éšæ§åˆ¶**ï¼šTemperatureã€Top-p å’Œæ¡æ¨£ç­–ç•¥åƒæ•¸
- **ğŸ¤– MCP ä¼ºæœå™¨**ï¼šModel Context Protocol ä¼ºæœå™¨ç”¨æ–¼ AI ä»£ç†æ•´åˆ

### ğŸ†• æ–°å¢ç‰¹æ€§
- Whisper è‡ªå‹•è½‰éŒ„ï¼ˆåƒè€ƒæ–‡å­—ç•™ç©ºå³å¯ï¼‰
- å³æ™‚ç”Ÿæˆé€²åº¦èˆ‡è¨ˆæ™‚
- å¯¦é©—æ€§é€²éšåƒæ•¸
- æª”æ¡ˆå„²å­˜åœ¨ä¸»æ©Ÿ `/tmp/glm-tts-voices`
- å®Œæ•´çš„ ONNX Runtime GPU åŠ é€Ÿï¼ˆcuDNN 9ï¼‰
- MCP ä¼ºæœå™¨ç„¡ç¸«æ•´åˆ AI ä»£ç†

## ğŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆæ¨è–¦ï¼‰

### ä½¿ç”¨ Dockerï¼ˆä¸€é«”åŒ–æ˜ åƒï¼‰

```bash
# æ‹‰å–æœ€æ–° v2.3.1 æ˜ åƒ
docker pull neosun/glm-tts:all-in-one-fastapi-v2.3.1

# å»ºç«‹è‡¨æ™‚ç›®éŒ„
mkdir -p /tmp/glm-tts-voices
chmod 777 /tmp/glm-tts-voices

# ä½¿ç”¨ GPU 0 åŸ·è¡Œï¼ˆæ ¹æ“šéœ€è¦æ›´æ”¹è£ç½® IDï¼‰
docker run -d \
  --name glm-tts \
  --runtime=nvidia \
  -e NVIDIA_VISIBLE_DEVICES=0 \
  -e PORT=8080 \
  -e TEMP_DIR=/tmp/glm-tts-voices \
  -p 8080:8080 \
  -v /tmp/glm-tts-voices:/tmp/glm-tts-voices \
  --restart unless-stopped \
  neosun/glm-tts:all-in-one-fastapi-v2.3.1
```

**å­˜å– Web ä»‹é¢**ï¼š`http://localhost:8080`

### ä½¿ç”¨ Docker Compose

```yaml
version: '3.8'

services:
  glm-tts:
    image: neosun/glm-tts:all-in-one
    container_name: glm-tts
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - PORT=8080
      - TEMP_DIR=/tmp/glm-tts-voices
    ports:
      - "8080:8080"
    volumes:
      - /tmp/glm-tts-voices:/tmp/glm-tts-voices
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
```

å•Ÿå‹•æœå‹™ï¼š
```bash
docker-compose up -d
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### Web ä»‹é¢

1. åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿ `http://localhost:8080`
2. ä¸Šå‚³åƒè€ƒéŸ³è¨Šæª”æ¡ˆï¼ˆ3-10 ç§’ï¼ŒWAV æ ¼å¼ï¼‰
3. è¼¸å…¥è¦åˆæˆçš„æ–‡å­—
4. **å¯é¸**ï¼šåƒè€ƒæ–‡å­—ç•™ç©ºï¼Œé€é Whisper è‡ªå‹•è½‰éŒ„
5. **å¯é¸**ï¼šå±•é–‹ã€Œé€²éšåƒæ•¸ã€é€²è¡Œå¾®èª¿
6. é»æ“Šã€Œç”ŸæˆèªéŸ³ã€ä¸¦è§€å¯Ÿå³æ™‚é€²åº¦
7. ä¸‹è¼‰ç”Ÿæˆçš„éŸ³è¨Š

### REST API

**ç”ŸæˆèªéŸ³ï¼š**

```bash
curl -X POST http://localhost:8080/api/tts \
  -F "text=ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦ã€‚" \
  -F "prompt_audio=@reference.wav" \
  -F "prompt_text=åƒè€ƒéŸ³è¨Šæ–‡å­—" \
  -F "temperature=0.8" \
  -F "top_p=0.9" \
  -F "sampling_strategy=balanced"
```

**API æ–‡ä»¶**ï¼šå­˜å– `http://localhost:8080/apidocs` æª¢è¦–äº’å‹•å¼ Swagger æ–‡ä»¶ã€‚

**å¥åº·æª¢æŸ¥ï¼š**
```bash
curl http://localhost:8080/health
```

### MCP ä¼ºæœå™¨æ•´åˆ

å°ˆæ¡ˆåŒ…å« MCPï¼ˆModel Context Protocolï¼‰ä¼ºæœå™¨ç”¨æ–¼ AI ä»£ç†æ•´åˆï¼š

```bash
# å•Ÿå‹• MCP ä¼ºæœå™¨
python mcp_server.py

# åœ¨ AI ä»£ç†ä¸­è¨­å®šï¼ˆä¾‹å¦‚ Claude Desktopï¼‰
# è©³è¦‹ MCP_GUIDE.md
```

### é€²éšåƒæ•¸

- **Temperature** (0.1-1.5)ï¼šæ§åˆ¶éš¨æ©Ÿæ€§ï¼ˆè¶Šé«˜è¶Šå¤šæ¨£åŒ–ï¼‰
- **Top-p** (0.5-1.0)ï¼šæ ¸æ¡æ¨£é–¾å€¼
- **æ¡æ¨£ç­–ç•¥**ï¼š
  - `fast`ï¼šå¿«é€Ÿç”Ÿæˆï¼Œå“è³ªè¼ƒä½
  - `balanced`ï¼šé è¨­ï¼Œå“è³ª/é€Ÿåº¦å¹³è¡¡
  - `quality`ï¼šæœ€ä½³å“è³ªï¼Œç”Ÿæˆè¼ƒæ…¢
- **è·³é Whisper**ï¼šåœç”¨è‡ªå‹•è½‰éŒ„ä»¥åŠ å¿«è™•ç†

## ğŸ—ï¸ æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI        â”‚
â”‚  (HTML/JS)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask ä¼ºæœå™¨   â”‚
â”‚  (server.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TTS å¼•æ“       â”‚
â”‚ (tts_engine.py) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
â”‚Whisperâ”‚  â”‚GLM-TTSâ”‚
â”‚ æ¨¡å‹  â”‚  â”‚ æ¨¡å‹  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¢å¼·å…ƒä»¶

| å…ƒä»¶ | èªªæ˜ |
|------|------|
| `server.py` | Flask REST API èˆ‡ SSE é€²åº¦æµ |
| `tts_engine.py` | TTS æ¨ç†å¼•æ“èˆ‡ Whisper æ•´åˆ |
| `mcp_server.py` | MCP ä¼ºæœå™¨ç”¨æ–¼ AI ä»£ç†æ•´åˆ |
| `Dockerfile` | å¤šéšæ®µå»ºç½®èˆ‡ cuDNN 9 |
| `docker-compose.yml` | ç”Ÿç”¢éƒ¨ç½²è¨­å®š |

## ğŸ”§ è¨­å®š

### ç’°å¢ƒè®Šæ•¸

| è®Šæ•¸ | é è¨­å€¼ | èªªæ˜ |
|------|--------|------|
| `PORT` | 8080 | ä¼ºæœå™¨åŸ  |
| `TEMP_DIR` | `/tmp/glm-tts-voices` | è‡¨æ™‚æª”æ¡ˆå„²å­˜ |
| `GPU_IDLE_TIMEOUT` | 60 | GPU é–’ç½®é€¾æ™‚ï¼ˆç§’ï¼‰ |
| `NVIDIA_VISIBLE_DEVICES` | 0 | GPU è£ç½® ID |

### GPU é¸æ“‡

ä½¿ç”¨ç‰¹å®š GPUï¼ˆä¾‹å¦‚ GPU 2ï¼‰ï¼š

```bash
docker run -e NVIDIA_VISIBLE_DEVICES=2 ...
```

æˆ–åœ¨ `docker-compose.yml` ä¸­ï¼š
```yaml
environment:
  - NVIDIA_VISIBLE_DEVICES=2
deploy:
  resources:
    reservations:
      devices:
        - device_ids: ['2']
```

## ğŸ“Š æ•ˆèƒ½

- **æ¨¡å‹å¤§å°**ï¼š23.6GBï¼ˆv2.3.1ä¸€é«”åŒ–æ˜ åƒï¼‰
- **é¡¯å­˜ä½¿ç”¨**ï¼šæ¨ç†æ™‚ç´„ 12GB
- **ç”Ÿæˆé€Ÿåº¦**ï¼š10ç§’éŸ³è¨Šéœ€2-3ç§’ï¼ˆæ¯”v2.0.0å¿«20-30å€ï¼‰
- **Whisper é–‹éŠ·**ï¼šè‡ªå‹•è½‰éŒ„å¢åŠ  2-3 ç§’
- **å•Ÿå‹•æ™‚é–“**ï¼šç´„90ç§’ï¼ˆä¸€æ¬¡æ€§æ¨¡å‹è¼‰å…¥ï¼‰
- **æ¨¡å‹å¿«å–**ï¼šæ‰€æœ‰æ¨¡å‹å¸¸é§GPUè¨˜æ†¶é«”ï¼Œå¯¦ç¾å³æ™‚æ¨ç†

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

**CUDA è¨˜æ†¶é«”ä¸è¶³**
- ä½¿ç”¨æ›´å¤§é¡¯å­˜çš„ GPUï¼ˆæ¨è–¦ 16GB+ï¼‰
- é—œé–‰å…¶ä»– GPU æ‡‰ç”¨ç¨‹å¼

**cuDNN ç‰ˆæœ¬ä¸ç¬¦**
- ä½¿ç”¨æä¾›çš„ Docker æ˜ åƒï¼ˆå·²åŒ…å« cuDNN 9ï¼‰
- æª¢æŸ¥ï¼š`ldconfig -p | grep cudnn`

**ç”Ÿæˆç·©æ…¢**
- é©—è­‰ GPU ä½¿ç”¨ï¼š`nvidia-smi`
- æª¢æŸ¥ NVIDIA_VISIBLE_DEVICES æ˜¯å¦ç¬¦åˆæ‚¨çš„ GPU

**Whisper å¤±æ•—**
- ç¢ºä¿éŸ³è¨Šæ¸…æ™°ä¸”æ ¼å¼å—æ”¯æ´
- ä½¿ç”¨ `skip_whisper=true` ç¹é

## ğŸ“¦ å¾åŸå§‹ç¢¼å»ºç½®

```bash
# å»ºç½® Docker æ˜ åƒ
docker build -t glm-tts:custom .

# æ¨é€åˆ°å„²å­˜åº«
docker tag glm-tts:custom your-registry/glm-tts:latest
docker push your-registry/glm-tts:latest
```

## ğŸ¤ è²¢ç»

æ­¡è¿è²¢ç»ï¼è«‹ï¼š

1. Fork å„²å­˜åº«
2. å»ºç«‹åŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. é–‹å•Ÿ Pull Request

## ğŸ“ æ›´æ–°æ—¥èªŒ

### v2.3.1 (2025-12-13)
- âš¡ **20-30å€æ•ˆèƒ½æå‡**ï¼šæ¨ç†æ™‚é–“å¾60ç§’é™è‡³2-3ç§’
- ğŸ—ï¸ æ¶æ§‹é‡æ§‹ï¼šTTSEngineç›´æ¥è¼‰å…¥æ¨¡å‹ï¼Œæ¶ˆé™¤subprocessé–‹éŠ·
- ğŸ’¾ æ¨¡å‹å¸¸é§GPUè¨˜æ†¶é«”ï¼šæ‰€æœ‰æ¨¡å‹ï¼ˆWhisperã€LLMã€Flowï¼‰é è¼‰å…¥ä¸¦å¿«å–
- ğŸ”§ ä¿®å¾©Flowæ¨¡å‹åŒ…è£ï¼šæ­£ç¢ºæ•´åˆToken2Wavå¯¦ç¾token2wav_with_cache
- ğŸ¤ å¢å¼·Whisperæ•´åˆï¼šæ”¯æ´skip_whisperåƒæ•¸çš„è‡ªå‹•è½‰éŒ„
- âœ… å®Œæ•´APIæ¸¬è©¦è¦†è“‹ï¼šé©—è­‰æ‰€æœ‰10å€‹APIç«¯é»ï¼ˆæ¨™æº–TTSã€ä¸²æµã€voice_idã€ä¸Šå‚³ï¼‰
- ğŸš€ ç”Ÿç”¢å°±ç·’ï¼šç©©å®šæ•ˆèƒ½ï¼Œç”Ÿæˆæ™‚é–“ç©©å®šåœ¨2-3ç§’

### v2.0.0 (2025-12-12)
- ğŸš€ SSEä¸²æµTTSï¼ˆä¼ºæœå™¨æ¨é€äº‹ä»¶ï¼‰
- âš¡ éåŒæ­¥æœ€ä½³åŒ–çš„é ç”Ÿæˆæ¶æ§‹
- ğŸµ å³æ™‚éŸ³è¨Šå€å¡Šå‚³è¼¸
- ğŸ”„ FastAPIæ¡†æ¶é·ç§»
- ğŸ“¡ æ¨™æº–å’Œä¸²æµTTSé›™æ¨¡å¼
- ğŸ¯ ç”Ÿç”¢å°±ç·’çš„ä¸²æµç®¡ç·š

### v1.0.0 (2025-12-12)
- âœ¨ åˆå§‹å¢å¼·ç‰ˆæœ¬ç™¼å¸ƒ
- ğŸŒ å³æ™‚é€²åº¦çš„ Web UI
- ğŸ”Œ REST API èˆ‡ Swagger æ–‡ä»¶
- ğŸ¤ Whisper è‡ªå‹•è½‰éŒ„
- ğŸ³ ä¸€é«”åŒ– Docker æ˜ åƒï¼ˆ20.5GBï¼‰
- âš¡ ONNX Runtime çš„ cuDNN 9 æ”¯æ´
- ğŸ’¾ ä¸»æ©Ÿæ›è¼‰å„²å­˜
- ğŸ”§ é€²éšåƒæ•¸æ§åˆ¶
- ğŸ¤– MCP ä¼ºæœå™¨æ•´åˆ

## ğŸ“„ æˆæ¬Š

Apache License 2.0 - è©³è¦‹ [LICENSE](LICENSE)

## ğŸ™ è‡´è¬

- [GLM-TTS](https://github.com/zai-org/GLM-TTS) - åŸå§‹ TTS æ¨¡å‹
- [OpenAI Whisper](https://github.com/openai/whisper) - èªéŸ³è­˜åˆ¥
- [CosyVoice](https://github.com/FunAudioLLM/CosyVoice) - å‰ç«¯æ¡†æ¶

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=neosun100/GLM-TTS-Enhanced&type=Date)](https://star-history.com/#neosun100/GLM-TTS-Enhanced)

## ğŸ“± é—œæ³¨å…¬çœ¾è™Ÿ

![å…¬çœ¾è™Ÿ](https://img.aws.xin/uPic/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-æ ‡å‡†è‰²ç‰ˆ.png)

---

**ç”± GLM-TTS å¢å¼·åœ˜éšŠç”¨ â¤ï¸ è£½ä½œ**
