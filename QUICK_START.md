# GLM-TTS å¿«é€Ÿå¼€å§‹ âš¡

## ä¸€åˆ†é’Ÿå¯åŠ¨

```bash
# 1. ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
huggingface-cli download zai-org/GLM-TTS --local-dir ckpt

# 2. å¯åŠ¨æœåŠ¡
./start.sh

# 3. è®¿é—®
# UI: http://0.0.0.0:8080
# API: http://0.0.0.0:8080/docs
```

## ä¸‰ç§ä½¿ç”¨æ–¹å¼

### ğŸ–¥ï¸ UI ç•Œé¢
```
æ‰“å¼€æµè§ˆå™¨ â†’ http://0.0.0.0:8080
ä¸Šä¼ éŸ³é¢‘ â†’ è¾“å…¥æ–‡æœ¬ â†’ ç”Ÿæˆ
```

### ğŸ”Œ API è°ƒç”¨
```bash
curl -X POST http://0.0.0.0:8080/api/tts \
  -F "text=ä½ å¥½" \
  -F "prompt_audio=@prompt.wav" \
  -o output.wav
```

### ğŸ¤– MCP é›†æˆ
```json
// æ·»åŠ åˆ° claude_desktop_config.json
{
  "mcpServers": {
    "glm-tts": {
      "command": "python3",
      "args": ["/path/to/mcp_server.py"]
    }
  }
}
```

## å¸¸ç”¨å‘½ä»¤

```bash
# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down

# é‡å¯
docker-compose restart

# æµ‹è¯•
./test_deployment.sh
```

## GPU ç®¡ç†

```bash
# æŸ¥çœ‹çŠ¶æ€
curl http://0.0.0.0:8080/api/gpu/status

# é‡Šæ”¾æ˜¾å­˜
curl -X POST http://0.0.0.0:8080/api/gpu/offload
```

## é…ç½®è°ƒæ•´

ç¼–è¾‘ `.env`:
```bash
PORT=8080              # ä¿®æ”¹ç«¯å£
GPU_IDLE_TIMEOUT=60    # GPU ç©ºé—²è¶…æ—¶
```

## é—®é¢˜æ’æŸ¥

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|---------|
| ç«¯å£å ç”¨ | ä¿®æ”¹ `.env` ä¸­çš„ `PORT` |
| GPU ä¸è¶³ | è°ƒç”¨ `/api/gpu/offload` |
| æ¨¡å‹ç¼ºå¤± | é‡æ–°ä¸‹è½½åˆ° `ckpt/` |
| å®¹å™¨å¤±è´¥ | æ£€æŸ¥ `docker-compose logs` |

## æ–‡æ¡£ç´¢å¼•

- ğŸ“– [å®Œæ•´æ–‡æ¡£](DEPLOYMENT.md)
- ğŸ³ [Docker æŒ‡å—](README_DOCKER.md)
- ğŸ¤– [MCP æŒ‡å—](MCP_GUIDE.md)
- ğŸ“š [é¡¹ç›®ä¸»é¡µ](README.md)
