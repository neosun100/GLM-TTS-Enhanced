[English](README_ENHANCE.md) | [ç®€ä½“ä¸­æ–‡](README_ENHANCE_CN.md) | [ç¹é«”ä¸­æ–‡](README_ENHANCE_TW.md) | [æ—¥æœ¬èª](README_ENHANCE_JP.md)

# GLM-TTS å¢å¼ºç‰ˆï¼šç”Ÿäº§çº§ TTS æœåŠ¡ä¸ Web ç•Œé¢

[![Docker Hub](https://img.shields.io/docker/v/neosun/glm-tts?label=Docker%20Hub)](https://hub.docker.com/r/neosun/glm-tts)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![CUDA](https://img.shields.io/badge/CUDA-12.1-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![Python](https://img.shields.io/badge/Python-3.10--3.12-blue.svg)](https://www.python.org/)

[GLM-TTS](https://github.com/zai-org/GLM-TTS) çš„å¢å¼ºç‰ˆæœ¬ï¼Œæä¾›ç”Ÿäº§çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ Web UIã€REST APIã€è‡ªåŠ¨è½¬å½•å’Œ Docker éƒ¨ç½²ã€‚

## âœ¨ å¢å¼ºåŠŸèƒ½

### ğŸ¯ æ ¸å¿ƒå¢å¼º
- **ğŸŒ Web ç•Œé¢**ï¼šç°ä»£åŒ–å“åº”å¼ç•Œé¢ï¼Œå®æ—¶è¿›åº¦è·Ÿè¸ª
- **ğŸ”Œ REST API**ï¼šå®Œæ•´çš„ API ä¸ Swagger æ–‡æ¡£
- **ğŸ¤ è‡ªåŠ¨è½¬å½•**ï¼šé›†æˆ Whisper è‡ªåŠ¨ç”Ÿæˆå‚è€ƒæ–‡æœ¬
- **ğŸ“Š å®æ—¶è¿›åº¦**ï¼šåŸºäº SSE çš„è¿›åº¦æµå¼ä¼ è¾“ä¸è®¡æ—¶ä¿¡æ¯
- **ğŸ³ Docker å°±ç»ª**ï¼šé¢„è£…æ‰€æœ‰ä¾èµ–çš„ä¸€ä½“åŒ– Docker é•œåƒ
- **âš¡ GPU ä¼˜åŒ–**ï¼šæ­£ç¡®çš„ GPU è®¾å¤‡æ˜ å°„å’Œ cuDNN 9 æ”¯æŒ
- **ğŸ’¾ æŒä¹…åŒ–å­˜å‚¨**ï¼šæŒ‚è½½å®¿ä¸»æœºç›®å½•è¿›è¡Œæ–‡ä»¶ç®¡ç†
- **ğŸ”§ é«˜çº§æ§åˆ¶**ï¼šTemperatureã€Top-p å’Œé‡‡æ ·ç­–ç•¥å‚æ•°

### ğŸ†• æ–°å¢ç‰¹æ€§
- **Whisper è‡ªåŠ¨è½¬å½•**ï¼šå‚è€ƒæ–‡æœ¬ç•™ç©ºæ—¶è‡ªåŠ¨ä»éŸ³é¢‘è¯†åˆ«
- **è¿›åº¦è·Ÿè¸ª**ï¼šå®æ—¶ç”Ÿæˆè¿›åº¦ä¸è€—æ—¶æ˜¾ç¤º
- **é«˜çº§å‚æ•°**ï¼šå®éªŒæ€§æ§åˆ¶ç”¨äºå¾®è°ƒè¾“å‡ºè´¨é‡
- **æ”¹è¿›å­˜å‚¨**ï¼šæ–‡ä»¶å­˜å‚¨åœ¨å®¿ä¸»æœº `/tmp/glm-tts-voices`
- **cuDNN 9 æ”¯æŒ**ï¼šå®Œæ•´çš„ ONNX Runtime GPU åŠ é€Ÿ
- **ä¸€ä½“åŒ–é•œåƒ**ï¼š20.5GB Docker é•œåƒåŒ…å«æ‰€æœ‰æ¨¡å‹

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šDockerï¼ˆæ¨èï¼‰

æ‹‰å–å¹¶è¿è¡Œä¸€ä½“åŒ–é•œåƒï¼š

```bash
# æ‹‰å–é•œåƒ
docker pull neosun/glm-tts:all-in-one

# åˆ›å»ºä¸´æ—¶ç›®å½•
mkdir -p /tmp/glm-tts-voices
chmod 777 /tmp/glm-tts-voices

# ä½¿ç”¨ GPU 0 è¿è¡Œï¼ˆæ ¹æ®éœ€è¦æ›´æ”¹è®¾å¤‡ IDï¼‰
docker run -d \
  --name glm-tts \
  --runtime=nvidia \
  -e NVIDIA_VISIBLE_DEVICES=0 \
  -e PORT=8080 \
  -e TEMP_DIR=/tmp/glm-tts-voices \
  -p 8080:8080 \
  -v /tmp/glm-tts-voices:/tmp/glm-tts-voices \
  --restart unless-stopped \
  neosun/glm-tts:all-in-one
```

è®¿é—® Web ç•Œé¢ï¼š`http://localhost:8080`

### æ–¹å¼äºŒï¼šDocker Compose

åˆ›å»º `docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  glm-tts:
    image: neosun/glm-tts:all-in-one
    container_name: glm-tts
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0  # åœ¨æ­¤æ›´æ”¹ GPU ID
      - PORT=8080
      - GPU_IDLE_TIMEOUT=60
      - TEMP_DIR=/tmp/glm-tts-voices
    ports:
      - "8080:8080"
    volumes:
      - /tmp/glm-tts-voices:/tmp/glm-tts-voices
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # åœ¨æ­¤æ›´æ”¹ GPU ID
              capabilities: [gpu]
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
docker-compose up -d
```

### æ–¹å¼ä¸‰ï¼šæ‰‹åŠ¨å®‰è£…

**å‰ç½®è¦æ±‚ï¼š**
- Python 3.10 - 3.12
- CUDA 12.1+
- cuDNN 9
- NVIDIA GPU 16GB+ æ˜¾å­˜

**å®‰è£…æ­¥éª¤ï¼š**

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/neosun100/GLM-TTS-Enhanced.git
cd GLM-TTS-Enhanced

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install flask flasgger flask-cors onnxruntime-gpu openai-whisper

# ä¸‹è½½æ¨¡å‹
mkdir -p ckpt
huggingface-cli download zai-org/GLM-TTS --local-dir ckpt

# å¯åŠ¨æœåŠ¡å™¨
python server.py
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### Web ç•Œé¢

1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ `http://localhost:8080`
2. ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼ˆ3-10 ç§’ï¼‰
3. è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬ï¼ˆæˆ–ç•™ç©ºå‚è€ƒæ–‡æœ¬ä»¥è‡ªåŠ¨è½¬å½•ï¼‰
4. ç‚¹å‡»"ç”Ÿæˆè¯­éŸ³"å¹¶è§‚å¯Ÿå®æ—¶è¿›åº¦
5. ä¸‹è½½ç”Ÿæˆçš„éŸ³é¢‘

### REST API

**ç”Ÿæˆè¯­éŸ³ï¼š**

```bash
curl -X POST http://localhost:8080/api/tts \
  -F "text=ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚" \
  -F "prompt_audio=@reference.wav" \
  -F "prompt_text=å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹" \
  -F "temperature=0.8" \
  -F "top_p=0.9" \
  -F "sampling_strategy=balanced"
```

**API æ–‡æ¡£ï¼š**

è®¿é—® `http://localhost:8080/apidocs` æŸ¥çœ‹äº¤äº’å¼ Swagger æ–‡æ¡£ã€‚

### é«˜çº§å‚æ•°

- **Temperature** (0.1-1.5)ï¼šæ§åˆ¶éšæœºæ€§ï¼ˆè¶Šé«˜è¶Šå¤šæ ·åŒ–ï¼‰
- **Top-p** (0.5-1.0)ï¼šæ ¸é‡‡æ ·é˜ˆå€¼
- **é‡‡æ ·ç­–ç•¥**ï¼š
  - `fast`ï¼šå¿«é€Ÿç”Ÿæˆï¼Œè´¨é‡è¾ƒä½
  - `balanced`ï¼šé»˜è®¤ï¼Œè´¨é‡/é€Ÿåº¦å¹³è¡¡
  - `quality`ï¼šæœ€ä½³è´¨é‡ï¼Œç”Ÿæˆè¾ƒæ…¢
- **è·³è¿‡ Whisper**ï¼šç¦ç”¨è‡ªåŠ¨è½¬å½•ä»¥åŠ å¿«å¤„ç†é€Ÿåº¦

## ğŸ—ï¸ æ¶æ„

### ç³»ç»Ÿç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI        â”‚
â”‚  (HTML/JS)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask æœåŠ¡å™¨   â”‚
â”‚  (server.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TTS å¼•æ“       â”‚
â”‚ (tts_engine.py) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
â”‚Whisperâ”‚  â”‚GLM-TTSâ”‚
â”‚ æ¨¡å‹  â”‚  â”‚ æ¨¡å‹  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¢å¼ºæ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `server.py` | Flask REST API ä¸ SSE è¿›åº¦æµ |
| `tts_engine.py` | TTS æ¨ç†å¼•æ“ä¸ Whisper é›†æˆ |
| `Dockerfile` | å¤šé˜¶æ®µæ„å»ºä¸ cuDNN 9 |
| `docker-compose.yml` | ç”Ÿäº§éƒ¨ç½²é…ç½® |
| `.gitignore` | å¢å¼ºä»¥æ’é™¤æ•æ„Ÿæ•°æ® |

## ğŸ”§ é…ç½®

### ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `PORT` | 8080 | æœåŠ¡å™¨ç«¯å£ |
| `TEMP_DIR` | `/tmp/glm-tts-voices` | ä¸´æ—¶æ–‡ä»¶å­˜å‚¨ |
| `GPU_IDLE_TIMEOUT` | 60 | GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰ |
| `NVIDIA_VISIBLE_DEVICES` | 0 | GPU è®¾å¤‡ ID |

### GPU é€‰æ‹©

ä½¿ç”¨ç‰¹å®š GPUï¼ˆä¾‹å¦‚ GPU 2ï¼‰ï¼š

**Docker Runï¼š**
```bash
docker run -e NVIDIA_VISIBLE_DEVICES=2 ...
```

**Docker Composeï¼š**
```yaml
environment:
  - NVIDIA_VISIBLE_DEVICES=2
deploy:
  resources:
    reservations:
      devices:
        - device_ids: ['2']
```

## ğŸ“Š æ€§èƒ½

- **æ¨¡å‹å¤§å°**ï¼š20.5GBï¼ˆä¸€ä½“åŒ–é•œåƒï¼‰
- **æ˜¾å­˜ä½¿ç”¨**ï¼šæ¨ç†æ—¶çº¦ 12GB
- **ç”Ÿæˆé€Ÿåº¦**ï¼š10 ç§’éŸ³é¢‘éœ€ 2-5 ç§’
- **Whisper å¼€é”€**ï¼šè‡ªåŠ¨è½¬å½•å¢åŠ  2-3 ç§’

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. CUDA å†…å­˜ä¸è¶³**
- å‡å°‘æ‰¹é‡å¤§å°æˆ–ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPU
- å…³é—­å…¶ä»– GPU å¯†é›†å‹åº”ç”¨

**2. cuDNN ç‰ˆæœ¬ä¸åŒ¹é…**
- ç¡®ä¿å®‰è£… cuDNN 9ï¼ˆDocker é•œåƒå·²åŒ…å«ï¼‰
- æ£€æŸ¥ï¼š`ldconfig -p | grep cudnn`

**3. ç”Ÿæˆç¼“æ…¢**
- éªŒè¯æ­£åœ¨ä½¿ç”¨ GPUï¼š`nvidia-smi`
- æ£€æŸ¥ NVIDIA_VISIBLE_DEVICES æ˜¯å¦åŒ¹é…æ‚¨çš„ GPU

**4. Whisper å¤±è´¥**
- ç¡®ä¿éŸ³é¢‘æ¸…æ™°ä¸”æ ¼å¼å—æ”¯æŒ
- ä½¿ç”¨ `skip_whisper=true` ç»•è¿‡è‡ªåŠ¨è½¬å½•

## ğŸ“¦ ä»æºç æ„å»º

```bash
# æ„å»º Docker é•œåƒ
docker build -t glm-tts:custom .

# æ¨é€åˆ°ä»“åº“
docker tag glm-tts:custom your-registry/glm-tts:latest
docker push your-registry/glm-tts:latest
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·ï¼š

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. æ‰“å¼€ Pull Request

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-12-12)
- âœ¨ åˆå§‹å¢å¼ºç‰ˆæœ¬å‘å¸ƒ
- ğŸŒ æ·»åŠ å®æ—¶è¿›åº¦çš„ Web UI
- ğŸ”Œ REST API ä¸ Swagger æ–‡æ¡£
- ğŸ¤ Whisper è‡ªåŠ¨è½¬å½•é›†æˆ
- ğŸ³ ä¸€ä½“åŒ– Docker é•œåƒï¼ˆ20.5GBï¼‰
- âš¡ ONNX Runtime çš„ cuDNN 9 æ”¯æŒ
- ğŸ’¾ å®¿ä¸»æœºæŒ‚è½½å­˜å‚¨ä»¥å®ç°æŒä¹…åŒ–
- ğŸ”§ é«˜çº§å‚æ•°æ§åˆ¶

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache License 2.0 è®¸å¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- [GLM-TTS](https://github.com/zai-org/GLM-TTS) - åŸå§‹ TTS æ¨¡å‹
- [OpenAI Whisper](https://github.com/openai/whisper) - è¯­éŸ³è¯†åˆ«
- [CosyVoice](https://github.com/FunAudioLLM/CosyVoice) - å‰ç«¯æ¡†æ¶

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=neosun100/GLM-TTS-Enhanced&type=Date)](https://star-history.com/#neosun100/GLM-TTS-Enhanced)

## ğŸ“± å…³æ³¨å…¬ä¼—å·

![å…¬ä¼—å·](https://img.aws.xin/uPic/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-æ ‡å‡†è‰²ç‰ˆ.png)

---

**ç”± GLM-TTS å¢å¼ºå›¢é˜Ÿç”¨ â¤ï¸ åˆ¶ä½œ**
